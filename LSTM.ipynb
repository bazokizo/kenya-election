{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOyIaLt83OGsdJcY/0a55nx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "83a0a64154a344b5acb6f57b58513992": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_3ac3c11452f641e09595f83e721c0e8a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_0e1fb649488448da9fdeacdd68c79a63",
              "IPY_MODEL_374942c68e2c4dd4b0b17b0454d3a538"
            ]
          }
        },
        "3ac3c11452f641e09595f83e721c0e8a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0e1fb649488448da9fdeacdd68c79a63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_78ae518320db4dc3aad812d1e2320926",
            "_dom_classes": [],
            "description": "  0%",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 271972,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1259,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fd5144522055418a945c8199594aa058"
          }
        },
        "374942c68e2c4dd4b0b17b0454d3a538": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_30a7c3fe85274d809d90f15228d3b690",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1259/271972 [02:50&lt;6:34:50, 11.43it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d140ea98f9cc48c198d6ce49e3e04c3e"
          }
        },
        "78ae518320db4dc3aad812d1e2320926": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fd5144522055418a945c8199594aa058": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "30a7c3fe85274d809d90f15228d3b690": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d140ea98f9cc48c198d6ce49e3e04c3e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sydney-machine-learning/sentimentanalysis-USelections/blob/main/LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lOePlIwuLGNf"
      },
      "source": [
        "# Sentiment Analysis using LSTM and Keras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Dyl3HLpLB70"
      },
      "source": [
        "import pandas as pd    # to load dataset\r\n",
        "import numpy as np     # for mathematic equation\r\n",
        "from nltk.corpus import stopwords   # to get collection of stopwords\r\n",
        "from sklearn.model_selection import train_test_split       # for splitting dataset\r\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer  # to encode text to int\r\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences   # to do padding or truncating\r\n",
        "from tensorflow.keras.models import Sequential     # the model\r\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense # layers of the architecture\r\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint   # save model\r\n",
        "from tensorflow.keras.models import load_model   # load saved model\r\n",
        "import re\r\n",
        "import tensorflow as tf\r\n",
        "import pandas as pd"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aHBrlQUoM9Gd",
        "outputId": "326a00f2-437b-4444-f3fa-c536458cfa82"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JBYdzfe0NLNG",
        "outputId": "b786c1f2-51df-48d3-8f1e-9d24e33f6183"
      },
      "source": [
        "data = pd.read_csv('/content/drive/MyDrive/US_elections/LSTM/IMDB Dataset.csv')\r\n",
        "\r\n",
        "print(data)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                                  review sentiment\n",
            "0      One of the other reviewers has mentioned that ...  positive\n",
            "1      A wonderful little production. <br /><br />The...  positive\n",
            "2      I thought this was a wonderful way to spend ti...  positive\n",
            "3      Basically there's a family where a little boy ...  negative\n",
            "4      Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
            "...                                                  ...       ...\n",
            "49995  I thought this movie did a down right good job...  positive\n",
            "49996  Bad plot, bad dialogue, bad acting, idiotic di...  negative\n",
            "49997  I am a Catholic taught in parochial elementary...  negative\n",
            "49998  I'm going to have to disagree with the previou...  negative\n",
            "49999  No one expects the Star Trek movies to be high...  negative\n",
            "\n",
            "[50000 rows x 2 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IQvmimbaNT6O",
        "outputId": "74855b47-22c3-4e15-e325-785e49540163"
      },
      "source": [
        "\r\n",
        "import nltk\r\n",
        "nltk.download('stopwords')\r\n",
        "english_stops = set(stopwords.words('english'))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "apZjZEDaNcPg"
      },
      "source": [
        "## Load and Clean Dataset\r\n",
        "In the original dataset, the reviews are still dirty. There are still html tags, numbers, uppercase, and punctuations. This will not be good for training, so in load_dataset() function, beside loading the dataset using pandas, I also pre-process the reviews by removing html tags, non alphabet (punctuations and numbers), stop words, and lower case all of the reviews.\r\n",
        "\r\n",
        "## Encode Sentiments\r\n",
        "In the same function, I also encode the sentiments into integers (0 and 1). Where 0 is for negative sentiments and 1 is for positive sentiments."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8xYPJ3DNWZP",
        "outputId": "b25cf9d5-f7e1-45c3-cc34-93f66a5bc3d2"
      },
      "source": [
        "def load_dataset():\r\n",
        "    df = pd.read_csv('/content/drive/MyDrive/US_elections/LSTM/IMDB Dataset.csv')\r\n",
        "    x_data = df['review']       # Reviews/Input\r\n",
        "    y_data = df['sentiment']    # Sentiment/Output\r\n",
        "\r\n",
        "    # PRE-PROCESS REVIEW\r\n",
        "    x_data = x_data.replace({'<.*?>': ''}, regex = True)          # remove html tag\r\n",
        "    x_data = x_data.replace({'[^A-Za-z]': ' '}, regex = True)     # remove non alphabet\r\n",
        "    x_data = x_data.apply(lambda review: [w for w in review.split() if w not in english_stops])  # remove stop words\r\n",
        "    x_data = x_data.apply(lambda review: [w.lower() for w in review])   # lower case\r\n",
        "    \r\n",
        "    # ENCODE SENTIMENT -> 0 & 1\r\n",
        "    y_data = y_data.replace('positive', 1)\r\n",
        "    y_data = y_data.replace('negative', 0)\r\n",
        "\r\n",
        "    return x_data, y_data\r\n",
        "\r\n",
        "x_data, y_data = load_dataset()\r\n",
        "\r\n",
        "print('Reviews')\r\n",
        "print(x_data, '\\n')\r\n",
        "print('Sentiment')\r\n",
        "print(y_data)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reviews\n",
            "0        [one, reviewers, mentioned, watching, oz, epis...\n",
            "1        [a, wonderful, little, production, the, filmin...\n",
            "2        [i, thought, wonderful, way, spend, time, hot,...\n",
            "3        [basically, family, little, boy, jake, thinks,...\n",
            "4        [petter, mattei, love, time, money, visually, ...\n",
            "                               ...                        \n",
            "49995    [i, thought, movie, right, good, job, it, crea...\n",
            "49996    [bad, plot, bad, dialogue, bad, acting, idioti...\n",
            "49997    [i, catholic, taught, parochial, elementary, s...\n",
            "49998    [i, going, disagree, previous, comment, side, ...\n",
            "49999    [no, one, expects, star, trek, movies, high, a...\n",
            "Name: review, Length: 50000, dtype: object \n",
            "\n",
            "Sentiment\n",
            "0        1\n",
            "1        1\n",
            "2        1\n",
            "3        0\n",
            "4        1\n",
            "        ..\n",
            "49995    1\n",
            "49996    0\n",
            "49997    0\n",
            "49998    0\n",
            "49999    0\n",
            "Name: sentiment, Length: 50000, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GLZ24hlbNuik"
      },
      "source": [
        "## Split Dataset\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rb4AMEZONnHg",
        "outputId": "acde0a67-e1f9-4aec-fcb8-93b5db4d36b9"
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size = 0.2)\r\n",
        "\r\n",
        "print('Train Set')\r\n",
        "print(x_train, '\\n')\r\n",
        "print(x_test, '\\n')\r\n",
        "print('Test Set')\r\n",
        "print(y_train, '\\n')\r\n",
        "print(y_test)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Set\n",
            "18614    [honestly, think, best, version, war, worlds, ...\n",
            "3780     [this, film, plays, italian, family, romano, w...\n",
            "49913    [why, movie, fall, well, standards, ultimately...\n",
            "40444    [ulli, lommel, film, the, boogey, man, classic...\n",
            "36075    [this, one, movies, everything, i, think, i, w...\n",
            "                               ...                        \n",
            "8074     [just, great, soundtrack, really, enjoyable, m...\n",
            "5571     [i, could, name, plenty, funny, movies, there,...\n",
            "49436    [it, seems, incredible, decade, brought, star,...\n",
            "1225     [i, concur, users, comment, hard, believe, mov...\n",
            "37237    [i, writing, note, chess, player, well, movie,...\n",
            "Name: review, Length: 40000, dtype: object \n",
            "\n",
            "33820    [oh, going, little, one, little, one, turn, ar...\n",
            "24949    [there, lot, movies, set, release, dates, get,...\n",
            "48381    [all, world, stage, people, actors, something,...\n",
            "38819    [i, gonna, lie, to, say, movie, confusing, lik...\n",
            "24846    [beyond, shadow, doubt, mysterious, planet, on...\n",
            "                               ...                        \n",
            "19229    [televised, los, angeles, production, probably...\n",
            "14788    [i, recently, got, the, seven, ups, video, i, ...\n",
            "32006    [what, dreadful, movie, the, effects, poor, es...\n",
            "34985    [this, interesting, film, noir, features, thre...\n",
            "40854    [considering, john, doe, apparently, inspired,...\n",
            "Name: review, Length: 10000, dtype: object \n",
            "\n",
            "Test Set\n",
            "18614    1\n",
            "3780     1\n",
            "49913    0\n",
            "40444    0\n",
            "36075    1\n",
            "        ..\n",
            "8074     1\n",
            "5571     0\n",
            "49436    0\n",
            "1225     0\n",
            "37237    0\n",
            "Name: sentiment, Length: 40000, dtype: int64 \n",
            "\n",
            "33820    1\n",
            "24949    0\n",
            "48381    1\n",
            "38819    1\n",
            "24846    0\n",
            "        ..\n",
            "19229    1\n",
            "14788    1\n",
            "32006    0\n",
            "34985    1\n",
            "40854    0\n",
            "Name: sentiment, Length: 10000, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rUngYm-sNwoH"
      },
      "source": [
        "def get_max_length():\r\n",
        "    review_length = []\r\n",
        "    for review in x_train:\r\n",
        "        review_length.append(len(review))\r\n",
        "\r\n",
        "    return int(np.ceil(np.mean(review_length)))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zW6qbnhYN4dN"
      },
      "source": [
        "## Tokenize and Pad/Truncate Reviews\r\n",
        "\r\n",
        "A Neural Network only accepts numeric data, so we need to encode the reviews. I use tensorflow.keras.preprocessing.text.Tokenizer to encode the reviews into integers, where each unique word is automatically indexed (using fit_on_texts method) based on x_train.\r\n",
        "x_train and x_test is converted into integers using texts_to_sequences method.\r\n",
        "\r\n",
        "Each reviews has a different length, so we need to add padding (by adding 0) or truncating the words to the same length (in this case, it is the mean of all reviews length) using tensorflow.keras.preprocessing.sequence.pad_sequences.\r\n",
        "\r\n",
        "post, pad or truncate the words in the back of a sentence\r\n",
        "pre, pad or truncate the words in front of a sentence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "99kzmaqQN11r",
        "outputId": "58ab3c20-7cde-4e6c-eaa7-df8abc5dabf9"
      },
      "source": [
        "\r\n",
        "# ENCODE REVIEW\r\n",
        "token = Tokenizer(lower=False)    # no need lower, because already lowered the data in load_data()\r\n",
        "token.fit_on_texts(x_train)\r\n",
        "x_train = token.texts_to_sequences(x_train)\r\n",
        "x_test = token.texts_to_sequences(x_test)\r\n",
        "\r\n",
        "max_length = get_max_length()\r\n",
        "\r\n",
        "x_train = pad_sequences(x_train, maxlen=max_length, padding='post', truncating='post')\r\n",
        "x_test = pad_sequences(x_test, maxlen=max_length, padding='post', truncating='post')\r\n",
        "\r\n",
        "total_words = len(token.word_index) + 1   # add 1 because of 0 padding\r\n",
        "\r\n",
        "print('Encoded X Train\\n', x_train, '\\n')\r\n",
        "print('Encoded X Test\\n', x_test, '\\n')\r\n",
        "print('Maximum review length: ', max_length)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Encoded X Train\n",
            " [[ 1123    30    46 ...     0     0     0]\n",
            " [    8     4   215 ...     0     0     0]\n",
            " [  361     3   678 ...  3148  1239     6]\n",
            " ...\n",
            " [    7    95   972 ...    11 13480     2]\n",
            " [    1 17324  5959 ...     0     0     0]\n",
            " [    1   401   777 ...   251  1138   160]] \n",
            "\n",
            "Encoded X Test\n",
            " [[  323    80    48 ...     0     0     0]\n",
            " [   50    82    28 ...  5711  3545  3485]\n",
            " [  199    85   852 ...     0     0     0]\n",
            " ...\n",
            " [  106  1950     3 ...     0     0     0]\n",
            " [    8   126     4 ... 17502  7735   774]\n",
            " [  980   213 11353 ...     6    21  1772]] \n",
            "\n",
            "Maximum review length:  130\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VwdL42nCOCWu"
      },
      "source": [
        "## Build Architecture/Model\r\n",
        "\r\n",
        "**Embedding Layer:** in simple terms, it creates word vectors of each word in the word_index and group words that are related or have similar meaning by analyzing other words around them.\r\n",
        "\r\n",
        "**LSTM Layer:** to make a decision to keep or throw away data by considering the current input, previous output, and previous memory. There are some important components in LSTM.\r\n",
        "\r\n",
        "- **Forget Gate**, decides information is to be kept or thrown away\r\n",
        "- Input Gate, updates cell state by passing previous output and current input into sigmoid activation function\r\n",
        "- **Cell State**, calculate new cell state, it is multiplied by forget vector (drop value if multiplied by a near 0), add it with the output from input gate to update the cell state value.\r\n",
        "- **Ouput Gate**, decides the next hidden state and used for predictions\r\n",
        "\r\n",
        "**Dense Layer:** compute the input with the weight matrix and bias (optional), and using an activation function. I use Sigmoid activation function for this work because the output is only 0 or 1.\r\n",
        "\r\n",
        "The optimizer is Adam and the loss function is Binary Crossentropy because again the output is only 0 and 1, which is a binary number."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X9Jk16NAN-4u",
        "outputId": "cfbe292a-806f-4bbb-b452-e2c9f68f1bc2"
      },
      "source": [
        "\r\n",
        "# ARCHITECTURE\r\n",
        "EMBED_DIM = 32\r\n",
        "LSTM_OUT = 64\r\n",
        "\r\n",
        "model = Sequential()\r\n",
        "model.add(Embedding(total_words, EMBED_DIM, input_length = max_length))\r\n",
        "model.add(LSTM(LSTM_OUT))\r\n",
        "model.add(Dense(64, activation='relu'))\r\n",
        "model.add(Dense(1, activation='sigmoid'))\r\n",
        "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\r\n",
        "\r\n",
        "print(model.summary())"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 130, 32)           2943616   \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 64)                24832     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 2,972,673\n",
            "Trainable params: 2,972,673\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FwBwe39zOYJI"
      },
      "source": [
        "checkpoint = ModelCheckpoint(\r\n",
        "    '/content/drive/MyDrive/US_elections/LSTM/LSTM_2.h5',\r\n",
        "    monitor='accuracy',\r\n",
        "    save_best_only=True,\r\n",
        "    verbose=1\r\n",
        ")"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zvhj3IKdOjYj",
        "outputId": "f37eb015-6b85-4b4b-b3b3-69879e6c8e80"
      },
      "source": [
        "model.fit(x_train, y_train, batch_size = 128, epochs = 5, callbacks=[checkpoint])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "313/313 [==============================] - 20s 36ms/step - loss: 0.5609 - accuracy: 0.6473\n",
            "\n",
            "Epoch 00001: accuracy improved from -inf to 0.77410, saving model to /content/drive/MyDrive/US_elections/LSTM/LSTM_2.h5\n",
            "Epoch 2/5\n",
            "313/313 [==============================] - 11s 36ms/step - loss: 0.1871 - accuracy: 0.9326\n",
            "\n",
            "Epoch 00002: accuracy improved from 0.77410 to 0.92948, saving model to /content/drive/MyDrive/US_elections/LSTM/LSTM_2.h5\n",
            "Epoch 3/5\n",
            "313/313 [==============================] - 11s 36ms/step - loss: 0.1013 - accuracy: 0.9686\n",
            "\n",
            "Epoch 00003: accuracy improved from 0.92948 to 0.96562, saving model to /content/drive/MyDrive/US_elections/LSTM/LSTM_2.h5\n",
            "Epoch 4/5\n",
            "313/313 [==============================] - 11s 36ms/step - loss: 0.0563 - accuracy: 0.9835\n",
            "\n",
            "Epoch 00004: accuracy improved from 0.96562 to 0.97975, saving model to /content/drive/MyDrive/US_elections/LSTM/LSTM_2.h5\n",
            "Epoch 5/5\n",
            "313/313 [==============================] - 11s 36ms/step - loss: 0.0514 - accuracy: 0.9844\n",
            "\n",
            "Epoch 00005: accuracy improved from 0.97975 to 0.98350, saving model to /content/drive/MyDrive/US_elections/LSTM/LSTM_2.h5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fe4a2fff710>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I2cXl9vXOoHY"
      },
      "source": [
        "\r\n",
        "## Testing\r\n",
        "\r\n",
        "To evaluate the model, we need to predict the sentiment using our **x_test** data and comparing the predictions with y_test (expected output) data. Then, we calculate the accuracy of the model by dividing numbers of correct prediction with the total data. Resulted an accuracy of **86.63%**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OC-t2EwBOk8O",
        "outputId": "7fd94878-6082-41ef-fed6-85b3cc3014c0"
      },
      "source": [
        "\r\n",
        "y_pred = model.predict_classes(x_test, batch_size = 128)\r\n",
        "\r\n",
        "true = 0\r\n",
        "for i, y in enumerate(y_test):\r\n",
        "    if y == y_pred[i]:\r\n",
        "        true += 1\r\n",
        "\r\n",
        "print('Correct Prediction: {}'.format(true))\r\n",
        "print('Wrong Prediction: {}'.format(len(y_pred) - true))\r\n",
        "print('Accuracy: {}'.format(true/len(y_pred)*100))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Correct Prediction: 8658\n",
            "Wrong Prediction: 1342\n",
            "Accuracy: 86.58\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e9JT5lidP7XW"
      },
      "source": [
        "## Load Saved Model\r\n",
        "\r\n",
        "Load saved model and use it to predict a movie review statement's sentiment (positive or negative)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bkahGprwOxWI"
      },
      "source": [
        "loaded_model = load_model('/content/drive/MyDrive/US_elections/LSTM/LSTM.h5')"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fp0ShOc_QF0V"
      },
      "source": [
        "Receives a review as an input to be predicted"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "679dASPGQFLN",
        "outputId": "0cbff5ef-9c62-4795-f893-40fb45700055"
      },
      "source": [
        "review = str(input('Movie Review: '))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Movie Review: Nothing was typical about this. Everything was beautifully done in this movie, the story, the flow, the scenario, everything. I highly recommend it for mystery lovers, for anyone who wants to watch a good movie!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qV2VO1BpQOC0"
      },
      "source": [
        "The input must be pre processed before it is passed to the model to be predicted"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sblaYgLmQC6u",
        "outputId": "932b4fb5-97ef-44d4-b9ef-a13b9de7feb7"
      },
      "source": [
        "# Pre-process input\r\n",
        "regex = re.compile(r'[^a-zA-Z\\s]')\r\n",
        "review = regex.sub('', review)\r\n",
        "print('Cleaned: ', review)\r\n",
        "\r\n",
        "words = review.split(' ')\r\n",
        "filtered = [w for w in words if w not in english_stops]\r\n",
        "filtered = ' '.join(filtered)\r\n",
        "filtered = [filtered.lower()]\r\n",
        "\r\n",
        "print('Filtered: ', filtered)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cleaned:  Nothing was typical about this Everything was beautifully done in this movie the story the flow the scenario everything I highly recommend it for mystery lovers for anyone who wants to watch a good movie\n",
            "Filtered:  ['nothing typical everything beautifully done movie story flow scenario everything i highly recommend mystery lovers anyone wants watch good movie']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9HgxPTw6QPxX",
        "outputId": "a6389370-2a20-4fa8-df77-fe17e7abc7f7"
      },
      "source": [
        "tokenize_words = token.texts_to_sequences(filtered)\r\n",
        "tokenize_words = pad_sequences(tokenize_words, maxlen=max_length, padding='post', truncating='post')\r\n",
        "print(tokenize_words)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[  76  680  169 1188  125    3   15 2651 2642  169    1  444  285  706\n",
            "  1721  151  400   34    9    3    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AJvw15txQSqE",
        "outputId": "196217d9-be33-4464-c787-33875ace15d5"
      },
      "source": [
        "result = loaded_model.predict(tokenize_words)\r\n",
        "print(result)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.99802494]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3NumKa_UQVn1",
        "outputId": "2f47d133-1b08-417c-b734-fca00d353bc2"
      },
      "source": [
        "if result >= 0.7:\r\n",
        "    print('positive')\r\n",
        "else:\r\n",
        "    print('negative')"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "positive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exkkcbkzRg2W"
      },
      "source": [
        "# Testing this on tweet data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbw3zst_QZd4"
      },
      "source": [
        "# !pip install transformers command\r\n",
        "# from transformers import BertTokenizer, TFBertForSequenceClassification\r\n",
        "\r\n",
        "# model = TFBertForSequenceClassification.from_pretrained(\"bert-base-uncased\")\r\n",
        "# tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kgDdQQR2RmzL"
      },
      "source": [
        "loaded_model = load_model('/content/drive/MyDrive/US_elections/LSTM/LSTM.h5')"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "313k8fiBRrdW",
        "outputId": "a1133bf1-6b83-40f1-dab4-bd470eca2975"
      },
      "source": [
        "biden_df = pd.read_csv('/content/drive/MyDrive/US_elections/cleaned_sample_100_biden.csv')\r\n",
        "trump_df = pd.read_csv('/content/drive/MyDrive/US_elections/cleaned_sample_100_trump.csv')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (0,2,3) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n",
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (0,2) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 47
        },
        "id": "TZuBwtOASF9i",
        "outputId": "f0c1a5c0-1d01-4d4e-b942-688ab067bfa7"
      },
      "source": [
        "biden_df.loc[:,'who'] = 'biden'\r\n",
        "trump_df.loc[:,'who'] = 'trump'\r\n",
        "\r\n",
        "balance_data_df = pd.DataFrame(columns=trump_df.columns)\r\n",
        "balance_data_df"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>tweet</th>\n",
              "      <th>long</th>\n",
              "      <th>lat</th>\n",
              "      <th>state_code</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>who</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [user_id, tweet, long, lat, state_code, sentiment, who]\n",
              "Index: []"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J5MvrHJZSIkr"
      },
      "source": [
        "states_list = set(biden_df['state_code']).union(set(trump_df['state_code'])) - set(['MP', 'GU', 'PR', 'VI', 'AS', 'UM', ])"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5gH4KZ4SPOj"
      },
      "source": [
        "for state in states_list:\r\n",
        "    trump_df_state = trump_df[trump_df['state_code']==state]\r\n",
        "    biden_df_state = biden_df[biden_df['state_code']==state]\r\n",
        "    \r\n",
        "    n_sample = len(trump_df_state) if len(trump_df_state) < len(biden_df_state) else len(biden_df_state)\r\n",
        "    \r\n",
        "    if len(trump_df_state) < len(biden_df_state):\r\n",
        "        balance_data_df = pd.concat([balance_data_df, trump_df_state])\r\n",
        "        balance_data_df = pd.concat([balance_data_df, biden_df_state.sample(len(trump_df_state))])\r\n",
        "    else:\r\n",
        "        balance_data_df = pd.concat([balance_data_df, biden_df_state])\r\n",
        "        balance_data_df = pd.concat([balance_data_df, trump_df_state.sample(len(biden_df_state))])"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "DHBiBy5NSQoo",
        "outputId": "e3f34f39-57c9-48fc-fd50-8a916beb9680"
      },
      "source": [
        "balance_data_df"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>tweet</th>\n",
              "      <th>long</th>\n",
              "      <th>lat</th>\n",
              "      <th>state_code</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>who</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>114</th>\n",
              "      <td>2753121.0</td>\n",
              "      <td>Trump acolyte Matt Gaetz has COVID. How many i...</td>\n",
              "      <td>-84.6824346</td>\n",
              "      <td>43.6212</td>\n",
              "      <td>MI</td>\n",
              "      <td>0.0</td>\n",
              "      <td>biden</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1641</th>\n",
              "      <td>13160892.0</td>\n",
              "      <td>The driver of the Trump Unity Bridge truck is ...</td>\n",
              "      <td>-83.04664029999998</td>\n",
              "      <td>42.3316</td>\n",
              "      <td>MI</td>\n",
              "      <td>0.0</td>\n",
              "      <td>biden</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1660</th>\n",
              "      <td>13566802.0</td>\n",
              "      <td>Trump</td>\n",
              "      <td>-84.6824346</td>\n",
              "      <td>43.6212</td>\n",
              "      <td>MI</td>\n",
              "      <td>0.0</td>\n",
              "      <td>biden</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1661</th>\n",
              "      <td>13566802.0</td>\n",
              "      <td>The American people demand answers JoeBiden di...</td>\n",
              "      <td>-84.6824346</td>\n",
              "      <td>43.6212</td>\n",
              "      <td>MI</td>\n",
              "      <td>0.0</td>\n",
              "      <td>biden</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1731</th>\n",
              "      <td>13849772.0</td>\n",
              "      <td>Fact check. Biden HunterBiden And there's WAY ...</td>\n",
              "      <td>-83.7312291</td>\n",
              "      <td>42.2682</td>\n",
              "      <td>MI</td>\n",
              "      <td>0.0</td>\n",
              "      <td>biden</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69622</th>\n",
              "      <td>449384057.0</td>\n",
              "      <td>Since were a week away from Election Day, Ner...</td>\n",
              "      <td>-121.8622122</td>\n",
              "      <td>47.4873</td>\n",
              "      <td>WA</td>\n",
              "      <td>0.0</td>\n",
              "      <td>biden</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15294</th>\n",
              "      <td>22671315.0</td>\n",
              "      <td>My coverage of seattleprotests downtown  Pione...</td>\n",
              "      <td>-122.3300624</td>\n",
              "      <td>47.6038</td>\n",
              "      <td>WA</td>\n",
              "      <td>0.0</td>\n",
              "      <td>biden</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6557</th>\n",
              "      <td>16670809.0</td>\n",
              "      <td>Watch it....trump doesn't like being FactCheck...</td>\n",
              "      <td>-122.6744557</td>\n",
              "      <td>45.6307</td>\n",
              "      <td>WA</td>\n",
              "      <td>0.0</td>\n",
              "      <td>biden</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28254</th>\n",
              "      <td>42293767.0</td>\n",
              "      <td>marketman52 championanimal Dang, I was trying ...</td>\n",
              "      <td>-122.1923372</td>\n",
              "      <td>47.6144</td>\n",
              "      <td>WA</td>\n",
              "      <td>0.0</td>\n",
              "      <td>biden</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>400832</th>\n",
              "      <td>1.25968055536239e+18</td>\n",
              "      <td>Donald is AS COLD AS ICE, WILLING TO SACRIFICE...</td>\n",
              "      <td>-123.04</td>\n",
              "      <td>48.07481420000001</td>\n",
              "      <td>WA</td>\n",
              "      <td>0.0</td>\n",
              "      <td>biden</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>271972 rows Ã— 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                     user_id  ...    who\n",
              "114                2753121.0  ...  biden\n",
              "1641              13160892.0  ...  biden\n",
              "1660              13566802.0  ...  biden\n",
              "1661              13566802.0  ...  biden\n",
              "1731              13849772.0  ...  biden\n",
              "...                      ...  ...    ...\n",
              "69622            449384057.0  ...  biden\n",
              "15294             22671315.0  ...  biden\n",
              "6557              16670809.0  ...  biden\n",
              "28254             42293767.0  ...  biden\n",
              "400832  1.25968055536239e+18  ...  biden\n",
              "\n",
              "[271972 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2xsP7PveSVyE"
      },
      "source": [
        "batch_size = 100"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mDINq9adSX0I"
      },
      "source": [
        "from tqdm.auto import tqdm\r\n",
        "import tensorflow as tf\r\n",
        "\r\n",
        "def emotion_classify(tweet_list):\r\n",
        "    # batch_idx = np.append(np.arange(0, len(tweet_list), batch_size), len(tweet_list))\r\n",
        "    labels = np.array([])\r\n",
        "    # print(batch_idx)\r\n",
        "\r\n",
        "# tokenize_words = token.texts_to_sequences(filtered)\r\n",
        "# tokenize_words = pad_sequences(tokenize_words, maxlen=max_length, padding='post', truncating='post')\r\n",
        "\r\n",
        "\r\n",
        "    for i in tqdm(range(len(tweet_list))):\r\n",
        "        tokenize_words = token.texts_to_sequences(tweet_list[i])\r\n",
        "        tokenize_words = pad_sequences(tokenize_words, maxlen=max_length, padding='post', truncating='post')\r\n",
        "        result = loaded_model.predict(tokenize_words)\r\n",
        "        labels = np.append(labels, tf.argmax(result, axis=1))\r\n",
        "        del tokenize_words\r\n",
        "\r\n",
        "    return labels"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382,
          "referenced_widgets": [
            "83a0a64154a344b5acb6f57b58513992",
            "3ac3c11452f641e09595f83e721c0e8a",
            "0e1fb649488448da9fdeacdd68c79a63",
            "374942c68e2c4dd4b0b17b0454d3a538",
            "78ae518320db4dc3aad812d1e2320926",
            "fd5144522055418a945c8199594aa058",
            "30a7c3fe85274d809d90f15228d3b690",
            "d140ea98f9cc48c198d6ce49e3e04c3e"
          ]
        },
        "id": "JjmXnQ7eTb-F",
        "outputId": "2b85fceb-514c-4a57-d1c7-a09bef3eeba1"
      },
      "source": [
        "# y_pred = loaded_model.predict_classes(balance_data_df['tweet'], batch_size = 128)\r\n",
        "\r\n",
        "balance_data_df['sentiment'] = emotion_classify(list(balance_data_df['tweet']))\r\n"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "83a0a64154a344b5acb6f57b58513992",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=271972.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-1b8c2f3b1379>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# y_pred = loaded_model.predict_classes(balance_data_df['tweet'], batch_size = 128)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mbalance_data_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sentiment'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0memotion_classify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbalance_data_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tweet'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-22-7209c1b8c217>\u001b[0m in \u001b[0;36memotion_classify\u001b[0;34m(tweet_list)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mtokenize_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtexts_to_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtweet_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mtokenize_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpad_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenize_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'post'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncating\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'post'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloaded_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenize_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mtokenize_words\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1623\u001b[0m       \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1624\u001b[0m       \u001b[0mbatch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1625\u001b[0;31m       \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menumerate_epochs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Single epoch.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1626\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_stop_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1627\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36menumerate_epochs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1131\u001b[0m     \u001b[0;34m\"\"\"Yields `(epoch, tf.data.Iterator)`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_truncate_execution_to_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1133\u001b[0;31m       \u001b[0mdata_iterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1134\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initial_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1135\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_insufficient_data\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Set by `catch_stop_iteration`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    420\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minside_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolocate_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 422\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0miterator_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOwnedIterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    423\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m       raise RuntimeError(\"__iter__() is only supported inside of tf.function \"\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset, components, element_spec)\u001b[0m\n\u001b[1;32m    680\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcomponents\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0melement_spec\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    681\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_message\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 682\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    683\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_create_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_create_iterator\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    703\u001b[0m               \u001b[0moutput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_output_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m               output_shapes=self._flat_output_shapes))\n\u001b[0;32m--> 705\u001b[0;31m       \u001b[0mgen_dataset_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_variant\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    706\u001b[0m       \u001b[0;31m# Delete the resource when this object is deleted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m       self._resource_deleter = IteratorResourceDeleter(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36mmake_iterator\u001b[0;34m(dataset, iterator, name)\u001b[0m\n\u001b[1;32m   2970\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2971\u001b[0m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0;32m-> 2972\u001b[0;31m         _ctx, \"MakeIterator\", name, dataset, iterator)\n\u001b[0m\u001b[1;32m   2973\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2974\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ephc-XU2TdtJ"
      },
      "source": [
        "dem_states = set(['DC', 'VT', 'HI', 'MA', 'MD', 'CA', 'NY', 'RI', 'DE', \r\n",
        "                 'CT', 'WA', 'ME', 'NJ', 'OR', 'IL'])\r\n",
        "rep_states = set(['OH', 'IA', 'TX', 'MT', 'SC', 'AK', 'MO', 'IN', 'NE',\r\n",
        "                 'KS', 'UT', 'MS', 'TN', 'SD', 'KY', 'LA', 'AL', 'ND',\r\n",
        "                 'ID', 'AR', 'OK', 'WV', 'WY'])\r\n",
        "swing_states = states_list - dem_states - rep_states"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckQHmc8MVibM"
      },
      "source": [
        "electoral_vote_by_state = pd.read_csv('/content/drive/MyDrive/US_elections/electoral_vote_by_state.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "agB4IH0cVlMG"
      },
      "source": [
        "states_results = pd.DataFrame(columns=['state_code', 'biden', 'trump', 'type', 'winner'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DFf63qDnVofN"
      },
      "source": [
        "states_results.loc[:,'state_code'] = electoral_vote_by_state['state_code']\r\n",
        "states_results.loc[:,'e_vote'] = electoral_vote_by_state['e_vote']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_FIA6MUZVo8q"
      },
      "source": [
        "type_vs_candidate = {'blue': 'biden', 'red': 'trump', 'purple': 'contentious'}\r\n",
        "threshold = 1.15\r\n",
        "for state in states_list:\r\n",
        "    trump_slice = balance_data_df.query(f'state_code == \"{state}\" and who == \"trump\"')\r\n",
        "    biden_slice = balance_data_df.query(f'state_code == \"{state}\" and who == \"biden\"')\r\n",
        "    trump_score = np.sum(trump_slice['sentiment']) + 1\r\n",
        "    biden_score = np.sum(biden_slice['sentiment']) + 1\r\n",
        "    \r\n",
        "    state_type = ''\r\n",
        "    if state in dem_states:\r\n",
        "        state_type = 'blue'\r\n",
        "    elif state in rep_states:\r\n",
        "        state_type = 'red'\r\n",
        "    else:\r\n",
        "        state_type = 'purple'\r\n",
        "        \r\n",
        "    winner = ''\r\n",
        "    if len(trump_slice) + len(biden_slice) < 1000:\r\n",
        "        winner = type_vs_candidate[state_type]\r\n",
        "    else:\r\n",
        "        if trump_score/biden_score > threshold:\r\n",
        "            winner = 'trump'\r\n",
        "        elif biden_score/trump_score > threshold:\r\n",
        "            winner = 'biden'\r\n",
        "        else:\r\n",
        "            winner = 'contentious'\r\n",
        "        \r\n",
        "    states_results.loc[states_results['state_code'] == state, ['biden', 'trump', 'type', 'winner']] = \\\r\n",
        "        [biden_score, trump_score, state_type, winner]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eY8cSzmtVqif"
      },
      "source": [
        "states_results.query('winner==\"contentious\"')\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8rPO66rQVuc2"
      },
      "source": [
        "import geopandas as gpd\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "us_shape = gpd.read_file('/content/drive/MyDrive/US_elections/us_shape/cb_2018_us_state_20m.shp')\r\n",
        "us_shape = us_shape[['STUSPS', 'geometry']]\r\n",
        "states_results_tmp = states_results.copy()\r\n",
        "states_results_tmp = states_results_tmp.merge(us_shape, left_on='state_code', right_on='STUSPS')\r\n",
        "states_results_tmp.drop(['STUSPS'], axis=1, inplace=True)\r\n",
        "states_results_tmp = gpd.GeoDataFrame(states_results_tmp)\r\n",
        "\r\n",
        "states_results_tmp.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ddf61jToV4xz"
      },
      "source": [
        "fig, ax = plt.subplots(1, 1, figsize=(15,15))\r\n",
        "states_results_tmp.apply(lambda x: ax.annotate(s=x.state_code, xy=x.geometry.centroid.coords[0], ha='center', fontsize=9, color='white'),axis=1);\r\n",
        "states_results_tmp[states_results_tmp['winner'] == 'trump'].plot(ax=ax, color='red')\r\n",
        "states_results_tmp[states_results_tmp['winner'] == 'biden'].plot(ax=ax, color='blue')\r\n",
        "states_results_tmp[states_results_tmp['winner'] == 'contentious'].plot(ax=ax, color='purple')\r\n",
        "plt.axis('square')\r\n",
        "ax.set_xlim([-180, -60])\r\n",
        "ax.set_ylim([10, 80])\r\n",
        "ax.set_xticks([])\r\n",
        "ax.set_yticks([])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h0C6yBAEV56v"
      },
      "source": [
        "states_results.to_csv('/content/drive/MyDrive/US_elections/state_results_LSTM.csv', index=False, header=True)\r\n",
        "fig.savefig('/content/drive/MyDrive/US_elections/state_results_LSTM.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iP51W2VcV_uO"
      },
      "source": [
        "trump_vote = np.sum(states_results[states_results['winner'] == 'trump']['e_vote'])\r\n",
        "biden_vote = np.sum(states_results[states_results['winner'] == 'biden']['e_vote'])\r\n",
        "print(trump_vote, biden_vote)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBaJkW5bWA-q"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}